#streamlit_app.py
# import streamlit as st
# import json
# import os
#
# # íŒŒì¼ ê²½ë¡œ ì„¤ì •
# file_path = "database/filtered_embedding_result.json"
#
# # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
# if not os.path.exists(file_path):
#     st.error(f"File not found: {file_path}")
# else:
#     # JSON íŒŒì¼ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
#     with open(file_path, "r") as f:
#         try:
#             filtered_embedding_result_json = json.load(f)
#         except json.JSONDecodeError as e:
#             st.error(f"Error decoding JSON: {e}")
#             filtered_embedding_result_json = []
#
#     # JSON ë°ì´í„° êµ¬ì¡° í™•ì¸ í›„ ì§ì ‘ í‘œì‹œ
#     if isinstance(filtered_embedding_result_json, list):
#         st.title("ì¶”ì²œ ë‰´ìŠ¤")
#
#         for doc in filtered_embedding_result_json:
#             # JSON ë°ì´í„°ì˜ metadataì—ì„œ title, source, summary ì¶”ì¶œ
#             metadata = doc.get("kwargs", {}).get("metadata", {})
#             title = metadata.get("title", "ì œëª© ì—†ìŒ")
#             link = metadata.get("source", "#")
#
#             # ì œëª©ì„ ë§í¬ë¡œ ë§Œë“¤ì–´ í‘œì‹œ
#             if link != "#":
#                 st.markdown(f"[{title}]({link})")
#             else:
#                 st.write(title)
#
#
#     else:
#         st.error("Unexpected JSON data structure.")

import streamlit as st
import json
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from dateutil import parser

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
file_path = "database/filtered_embedding_result.json"


def extract_news_details(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # ë‰´ìŠ¤ ë°œí–‰ ë‚ ì§œ ì¶”ì¶œ
            publish_date_element = (
                    soup.find('meta', {'property': 'article:published_time'}) or
                    soup.find('time', {'class': 'entry-date published'}) or
                    soup.find('time', {'class': 'tnt-date asset-date text-muted'}) or
                    soup.find('time', {'datetime': True}) or
                    soup.find('p', {'class': 'mb-no'})
            )
            if publish_date_element:
                if publish_date_element.has_attr('content'):
                    publish_date_str = publish_date_element['content']
                elif publish_date_element.has_attr('datetime'):
                    publish_date_str = publish_date_element['datetime']
                else:
                    publish_date_str = publish_date_element.text.strip()

                try:
                    # ë‚ ì§œë§Œ íŒŒì‹±(ì‹œê°„ ì œì™¸)
                    publish_date = parser.parse(publish_date_str, fuzzy=True).date().isoformat()
                except (ValueError, TypeError):
                    publish_date = "ë°œí–‰ ë‚ ì§œ ì—†ìŒ"
            else:
                publish_date = "ë°œí–‰ ë‚ ì§œ ì—†ìŒ"

            # ì¶œíŒì‚¬ ì¶”ì¶œ
            publisher = soup.find('meta', {'property': 'og:site_name'})
            if publisher and publisher.has_attr('content'):
                publisher = publisher['content']
            else:
                publisher = extract_publisher_from_url(url)

            return publish_date, publisher
        else:
            return "ë°œí–‰ ë‚ ì§œ ì—†ìŒ", extract_publisher_from_url(url)
    except Exception as e:
        st.error(f"Error extracting details from {url}: {e}")
        return "ë°œí–‰ ë‚ ì§œ ì—†ìŒ", extract_publisher_from_url(url)


def extract_publisher_from_url(url):
    try:
        domain = urlparse(url).netloc
        publisher = domain.split('.')[-2].capitalize()
        return publisher
    except Exception as e:
        st.error(f"Error extracting publisher from URL: {e}")
        return "ì¶œíŒì‚¬ ì—†ìŒ"


if not os.path.exists(file_path):
    st.error(f"File not found: {file_path}")
else:
    with open(file_path, "r") as f:
        try:
            filtered_embedding_result_json = json.load(f)
        except json.JSONDecodeError as e:
            st.error(f"Error decoding JSON: {e}")
            filtered_embedding_result_json = []

    if isinstance(filtered_embedding_result_json, list):
        st.title("ğŸ“–News recommender system")

        # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
        st.markdown(
            """
            <style>
            .st-emotion-cache-1wmy9hl.e1f1d6gn1 {
                max-width: 1200px; /* ì „ì²´ í˜ì´ì§€ì˜ ìµœëŒ€ ë„ˆë¹„ ì„¤ì • */
                margin-left: auto;
                margin-right: auto;
                padding-left: 0; /* ì¢Œì¸¡ ì—¬ë°± ì œê±° */
                padding-right: 0; /* ìš°ì¸¡ ì—¬ë°± ì œê±° */
            }
            .news-container {
                display: flex;
                justify-content: space-between;
                margin: 20px auto; /* ìƒí•˜ ì—¬ë°± 20px, ì¤‘ì•™ ì •ë ¬ */
                padding: 20px;
                border: 1px solid #e6e6e6;
                border-radius: 10px;
                width: 1000px; /* ì›í•˜ëŠ” ë„ˆë¹„ ì„¤ì • */
                box-sizing: border-box; /* íŒ¨ë”©ê³¼ í…Œë‘ë¦¬ë¥¼ ë„ˆë¹„ì— í¬í•¨ */
                margin-left: -15%; /* ì™¼ìª½ ì—¬ë°± ì¡°ì • */
            }
            .news-left {
                flex: 1; /* ë„ˆë¹„ ë¹„ìœ¨ ì¡°ì • */
                padding-right: 20px; /* ë‰´ìŠ¤ ë‚´ìš© ì˜ì—­ì˜ ìš°ì¸¡ ì—¬ë°± */
                margin-left: 0; /* ì™¼ìª½ ì—¬ë°± ì œê±° */
            }
            .news-right {
                flex: 1.5; /* ë‰´ìŠ¤ ìš”ì•½ ë¶€ë¶„ì˜ ë„ˆë¹„ë¥¼ ì¢€ ë” ë„“í˜ */
            }
            </style>
            """,
            unsafe_allow_html=True
        )

        for doc in filtered_embedding_result_json:
            # JSON ë°ì´í„°ì˜ metadataì—ì„œ title, source, summary ì¶”ì¶œ
            metadata = doc.get("kwargs", {}).get("metadata", {})
            title = metadata.get("title", "ì œëª© ì—†ìŒ")
            link = metadata.get("source", "#")

            if link != "#":
                publish_date, publisher = extract_news_details(link)
            else:
                publish_date, publisher = "ë°œí–‰ ë‚ ì§œ ì—†ìŒ", "ì¶œíŒì‚¬ ì—†ìŒ"

            st.markdown(
                f"""
                <div class="news-container">
                    <div class="news-left">
                        <h3><a href="{link}" target="_blank">{title}</a></h3>
                        <p>Date: {publish_date}</p>
                        <p>Publisher: {publisher}</p>
                    </div>
                    <div class="news-right">
                        <p>ë‰´ìŠ¤ ìš”ì•½ ê³µê°„</p>
                    </div>
                </div>
                """,
                unsafe_allow_html=True
            )
    else:
        st.error("Unexpected JSON data structure.")


